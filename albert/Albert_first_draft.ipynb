{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/aislinblack/CS6120-NLP-Project/blob/main/albert/Albert_first_draft.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ox2B6F1TehHK"
      },
      "outputs": [],
      "source": [
        ""
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "1qfQAtRsMVl7"
      },
      "source": [
        "# Question and Answering with ALBERT\n",
        "\n",
        "Based on the following jupyter notebook https://colab.research.google.com/github/spark-ming/albert-qa-demo/blob/master/Question_Answering_with_ALBERT.ipynb#scrollTo=1qfQAtRsMVl7\n",
        "\n",
        "## Introduction to ALBERT\n",
        "\n",
        "\n",
        "ALBERT stands for A Lite BERT and is a modified version of BERT NLP model. It builds on three key points such as Parameter Sharing, Embedding Factorization and Sentence Order Prediction (SOP). \n",
        "\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "sBBHbGvQN5vX"
      },
      "source": [
        "## 1.0 Setup\n",
        "\n",
        "Let's check out what kind of GPU our friends at Google gave us. This notebook should be configured to give you a P100 😃 (saved in metadata)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "frTeTcy4WdbY",
        "outputId": "1fded4e4-791f-4ae9-841a-1f414497a5b3"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Sat Aug 13 13:08:55 2022       \n",
            "+-----------------------------------------------------------------------------+\n",
            "| NVIDIA-SMI 460.32.03    Driver Version: 460.32.03    CUDA Version: 11.2     |\n",
            "|-------------------------------+----------------------+----------------------+\n",
            "| GPU  Name        Persistence-M| Bus-Id        Disp.A | Volatile Uncorr. ECC |\n",
            "| Fan  Temp  Perf  Pwr:Usage/Cap|         Memory-Usage | GPU-Util  Compute M. |\n",
            "|                               |                      |               MIG M. |\n",
            "|===============================+======================+======================|\n",
            "|   0  Tesla P100-PCIE...  Off  | 00000000:00:04.0 Off |                    0 |\n",
            "| N/A   40C    P0    29W / 250W |      0MiB / 16280MiB |      0%      Default |\n",
            "|                               |                      |                  N/A |\n",
            "+-------------------------------+----------------------+----------------------+\n",
            "                                                                               \n",
            "+-----------------------------------------------------------------------------+\n",
            "| Processes:                                                                  |\n",
            "|  GPU   GI   CI        PID   Type   Process name                  GPU Memory |\n",
            "|        ID   ID                                                   Usage      |\n",
            "|=============================================================================|\n",
            "|  No running processes found                                                 |\n",
            "+-----------------------------------------------------------------------------+\n"
          ]
        }
      ],
      "source": [
        "!nvidia-smi"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "D5RImM3oWbrZ"
      },
      "source": [
        "First, we clone the Hugging Face transformer library from Github"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "QOAoUwBFMQCg",
        "outputId": "d8159529-3a42-4ee2-e651-e73ae2d73686"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Cloning into 'transformers'...\n",
            "remote: Enumerating objects: 105690, done.\u001b[K\n",
            "remote: Counting objects: 100% (356/356), done.\u001b[K\n",
            "remote: Compressing objects: 100% (156/156), done.\u001b[K\n",
            "remote: Total 105690 (delta 199), reused 284 (delta 163), pack-reused 105334\u001b[K\n",
            "Receiving objects: 100% (105690/105690), 97.98 MiB | 30.12 MiB/s, done.\n",
            "Resolving deltas: 100% (78044/78044), done.\n",
            "Note: checking out 'a3085020ed0d81d4903c50967687192e3101e770'.\n",
            "\n",
            "You are in 'detached HEAD' state. You can look around, make experimental\n",
            "changes and commit them, and you can discard any commits you make in this\n",
            "state without impacting any branches by performing another checkout.\n",
            "\n",
            "If you want to create a new branch to retain commits you create, you may\n",
            "do so (now or later) by using -b with the checkout command again. Example:\n",
            "\n",
            "  git checkout -b <new-branch-name>\n",
            "\n",
            "HEAD is now at a3085020e Added repetition penalty to PPLM example (#2436)\n"
          ]
        }
      ],
      "source": [
        "!git clone https://github.com/huggingface/transformers \\\n",
        "&& cd transformers \\\n",
        "&& git checkout a3085020ed0d81d4903c50967687192e3101e770 "
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "TRZned-8WJrj",
        "outputId": "b8edc61d-c50f-4f72-d322-4c9f95498de8"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Processing ./transformers\n",
            "\u001b[33m  DEPRECATION: A future pip version will change local packages to be built in-place without first copying to a temporary directory. We recommend you use --use-feature=in-tree-build to test your packages with this new behavior before it becomes the default.\n",
            "   pip 21.3 will remove support for this functionality. You can find discussion regarding this at https://github.com/pypa/pip/issues/7555.\u001b[0m\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.7/dist-packages (from transformers==2.3.0) (1.21.6)\n",
            "Collecting tokenizers==0.0.11\n",
            "  Downloading tokenizers-0.0.11-cp37-cp37m-manylinux1_x86_64.whl (4.7 MB)\n",
            "\u001b[K     |████████████████████████████████| 4.7 MB 4.1 MB/s \n",
            "\u001b[?25hCollecting boto3\n",
            "  Downloading boto3-1.24.51-py3-none-any.whl (132 kB)\n",
            "\u001b[K     |████████████████████████████████| 132 kB 71.9 MB/s \n",
            "\u001b[?25hRequirement already satisfied: filelock in /usr/local/lib/python3.7/dist-packages (from transformers==2.3.0) (3.7.1)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.7/dist-packages (from transformers==2.3.0) (2.23.0)\n",
            "Requirement already satisfied: tqdm in /usr/local/lib/python3.7/dist-packages (from transformers==2.3.0) (4.64.0)\n",
            "Requirement already satisfied: regex!=2019.12.17 in /usr/local/lib/python3.7/dist-packages (from transformers==2.3.0) (2022.6.2)\n",
            "Collecting sentencepiece\n",
            "  Downloading sentencepiece-0.1.97-cp37-cp37m-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (1.3 MB)\n",
            "\u001b[K     |████████████████████████████████| 1.3 MB 54.3 MB/s \n",
            "\u001b[?25hCollecting sacremoses\n",
            "  Downloading sacremoses-0.0.53.tar.gz (880 kB)\n",
            "\u001b[K     |████████████████████████████████| 880 kB 62.3 MB/s \n",
            "\u001b[?25hCollecting botocore<1.28.0,>=1.27.51\n",
            "  Downloading botocore-1.27.51-py3-none-any.whl (9.0 MB)\n",
            "\u001b[K     |████████████████████████████████| 9.0 MB 53.7 MB/s \n",
            "\u001b[?25hCollecting jmespath<2.0.0,>=0.7.1\n",
            "  Downloading jmespath-1.0.1-py3-none-any.whl (20 kB)\n",
            "Collecting s3transfer<0.7.0,>=0.6.0\n",
            "  Downloading s3transfer-0.6.0-py3-none-any.whl (79 kB)\n",
            "\u001b[K     |████████████████████████████████| 79 kB 8.3 MB/s \n",
            "\u001b[?25hCollecting urllib3<1.27,>=1.25.4\n",
            "  Downloading urllib3-1.26.11-py2.py3-none-any.whl (139 kB)\n",
            "\u001b[K     |████████████████████████████████| 139 kB 74.2 MB/s \n",
            "\u001b[?25hRequirement already satisfied: python-dateutil<3.0.0,>=2.1 in /usr/local/lib/python3.7/dist-packages (from botocore<1.28.0,>=1.27.51->boto3->transformers==2.3.0) (2.8.2)\n",
            "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.7/dist-packages (from python-dateutil<3.0.0,>=2.1->botocore<1.28.0,>=1.27.51->boto3->transformers==2.3.0) (1.15.0)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.7/dist-packages (from requests->transformers==2.3.0) (2022.6.15)\n",
            "Requirement already satisfied: chardet<4,>=3.0.2 in /usr/local/lib/python3.7/dist-packages (from requests->transformers==2.3.0) (3.0.4)\n",
            "Requirement already satisfied: idna<3,>=2.5 in /usr/local/lib/python3.7/dist-packages (from requests->transformers==2.3.0) (2.10)\n",
            "  Downloading urllib3-1.25.11-py2.py3-none-any.whl (127 kB)\n",
            "\u001b[K     |████████████████████████████████| 127 kB 72.0 MB/s \n",
            "\u001b[?25hRequirement already satisfied: click in /usr/local/lib/python3.7/dist-packages (from sacremoses->transformers==2.3.0) (7.1.2)\n",
            "Requirement already satisfied: joblib in /usr/local/lib/python3.7/dist-packages (from sacremoses->transformers==2.3.0) (1.1.0)\n",
            "Building wheels for collected packages: transformers, sacremoses\n",
            "  Building wheel for transformers (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for transformers: filename=transformers-2.3.0-py3-none-any.whl size=458565 sha256=86aece926e1888fa5a31f954f73b524688f203dc6756936fb31238a71fbeb738\n",
            "  Stored in directory: /tmp/pip-ephem-wheel-cache-p7as8e6w/wheels/49/62/f4/6730819eed4e6468662b1519bf3bf46419b2335990c77f8767\n",
            "  Building wheel for sacremoses (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for sacremoses: filename=sacremoses-0.0.53-py3-none-any.whl size=895260 sha256=617fc40970da7c699238d719c8c4398e81340c9fcf2ddb71613411cac52b5dc5\n",
            "  Stored in directory: /root/.cache/pip/wheels/87/39/dd/a83eeef36d0bf98e7a4d1933a4ad2d660295a40613079bafc9\n",
            "Successfully built transformers sacremoses\n",
            "Installing collected packages: urllib3, jmespath, botocore, s3transfer, tokenizers, sentencepiece, sacremoses, boto3, transformers\n",
            "  Attempting uninstall: urllib3\n",
            "    Found existing installation: urllib3 1.24.3\n",
            "    Uninstalling urllib3-1.24.3:\n",
            "      Successfully uninstalled urllib3-1.24.3\n",
            "Successfully installed boto3-1.24.51 botocore-1.27.51 jmespath-1.0.1 s3transfer-0.6.0 sacremoses-0.0.53 sentencepiece-0.1.97 tokenizers-0.0.11 transformers-2.3.0 urllib3-1.25.11\n",
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Collecting tensorboardX\n",
            "  Downloading tensorboardX-2.5.1-py2.py3-none-any.whl (125 kB)\n",
            "\u001b[K     |████████████████████████████████| 125 kB 3.2 MB/s \n",
            "\u001b[?25hRequirement already satisfied: protobuf<=3.20.1,>=3.8.0 in /usr/local/lib/python3.7/dist-packages (from tensorboardX) (3.17.3)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.7/dist-packages (from tensorboardX) (1.21.6)\n",
            "Requirement already satisfied: six>=1.9 in /usr/local/lib/python3.7/dist-packages (from protobuf<=3.20.1,>=3.8.0->tensorboardX) (1.15.0)\n",
            "Installing collected packages: tensorboardX\n",
            "Successfully installed tensorboardX-2.5.1\n"
          ]
        }
      ],
      "source": [
        "!pip install ./transformers\n",
        "!pip install tensorboardX"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "UHCuzhPptH0M"
      },
      "source": [
        "## 2.0 Train Model\n",
        "\n",
        "Now, we could definitely train our own model (and you can see how to do that in the other linked jupyter notebook), but it would take a really long time, and because of this hugging face lets us borrow a pretrained albert model which was already trained on the SQuAD dataset.\n",
        "\n",
        "The tutorial lets us know that it takes about 1.5 hours per epoch to train ALBERT on SQuAD because the dataset is so large.\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "-JCNRkQwUD56"
      },
      "source": [
        "## 3.0 Setup prediction code\n",
        "\n",
        "Now we can use the Hugging Face library to make predictions using our newly trained model. Note that a lot of the code is pulled from `run_squad.py` in the Hugging Face repository, with all the training parts removed. This modified code allows to run predictions we pass in directly as strings, rather .json format like the training/test set.\n",
        "\n",
        "NOTE if you decided train your own mode, change the flag `use_own_model` to `True`\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 14,
      "metadata": {
        "cellView": "code",
        "id": "qp0Pq9z9Y4S0"
      },
      "outputs": [],
      "source": [
        "import os\n",
        "import torch\n",
        "import time\n",
        "from torch.utils.data import DataLoader, RandomSampler, SequentialSampler\n",
        "\n",
        "from transformers import (\n",
        "    AlbertConfig,\n",
        "    AlbertForQuestionAnswering,\n",
        "    AlbertTokenizer,\n",
        "    squad_convert_examples_to_features\n",
        ")\n",
        "\n",
        "from transformers.data.processors.squad import SquadResult, SquadV2Processor, SquadExample\n",
        "\n",
        "from transformers.data.metrics.squad_metrics import compute_predictions_logits\n",
        "\n",
        "# READER NOTE: Set this flag to use own model, or use pretrained model in the Hugging Face repository\n",
        "use_own_model = False\n",
        "\n",
        "if use_own_model:\n",
        "  model_name_or_path = \"/content/model_output\"\n",
        "else:\n",
        "  model_name_or_path = \"ktrapeznikov/albert-xlarge-v2-squad-v2\"\n",
        "\n",
        "output_dir = \"\"\n",
        "\n",
        "# Config\n",
        "n_best_size = 1\n",
        "max_answer_length = 30\n",
        "do_lower_case = True\n",
        "null_score_diff_threshold = 0.0\n",
        "\n",
        "def to_list(tensor):\n",
        "    return tensor.detach().cpu().tolist()\n",
        "\n",
        "# Setup model\n",
        "config_class, model_class, tokenizer_class = (\n",
        "    AlbertConfig, AlbertForQuestionAnswering, AlbertTokenizer)\n",
        "config = config_class.from_pretrained(model_name_or_path)\n",
        "tokenizer = tokenizer_class.from_pretrained(\n",
        "    model_name_or_path, do_lower_case=True)\n",
        "model = model_class.from_pretrained(model_name_or_path, config=config)\n",
        "\n",
        "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
        "\n",
        "model.to(device)\n",
        "\n",
        "processor = SquadV2Processor()\n",
        "\n",
        "def run_prediction(question_texts, context_text):\n",
        "    \"\"\"Setup function to compute predictions\"\"\"\n",
        "    examples = []\n",
        "\n",
        "    for i, question_text in enumerate(question_texts):\n",
        "        example = SquadExample(\n",
        "            qas_id=str(i),\n",
        "            question_text=question_text,\n",
        "            context_text=context_text,\n",
        "            answer_text=None,\n",
        "            start_position_character=None,\n",
        "            title=\"Predict\",\n",
        "            is_impossible=False,\n",
        "            answers=None,\n",
        "        )\n",
        "\n",
        "        examples.append(example)\n",
        "\n",
        "    features, dataset = squad_convert_examples_to_features(\n",
        "        examples=examples,\n",
        "        tokenizer=tokenizer,\n",
        "        max_seq_length=384,\n",
        "        doc_stride=128,\n",
        "        max_query_length=64,\n",
        "        is_training=False,\n",
        "        return_dataset=\"pt\",\n",
        "        threads=1,\n",
        "    )\n",
        "\n",
        "    eval_sampler = SequentialSampler(dataset)\n",
        "    eval_dataloader = DataLoader(dataset, sampler=eval_sampler, batch_size=10)\n",
        "\n",
        "    all_results = []\n",
        "\n",
        "    for batch in eval_dataloader:\n",
        "        model.eval()\n",
        "        batch = tuple(t.to(device) for t in batch)\n",
        "\n",
        "        with torch.no_grad():\n",
        "            inputs = {\n",
        "                \"input_ids\": batch[0],\n",
        "                \"attention_mask\": batch[1],\n",
        "                \"token_type_ids\": batch[2],\n",
        "            }\n",
        "\n",
        "            example_indices = batch[3]\n",
        "\n",
        "            outputs = model(**inputs)\n",
        "\n",
        "            for i, example_index in enumerate(example_indices):\n",
        "                eval_feature = features[example_index.item()]\n",
        "                unique_id = int(eval_feature.unique_id)\n",
        "\n",
        "                output = [to_list(output[i]) for output in outputs]\n",
        "\n",
        "                start_logits, end_logits = output\n",
        "                result = SquadResult(unique_id, start_logits, end_logits)\n",
        "                all_results.append(result)\n",
        "\n",
        "    output_prediction_file = \"predictions.json\"\n",
        "    output_nbest_file = \"nbest_predictions.json\"\n",
        "    output_null_log_odds_file = \"null_predictions.json\"\n",
        "\n",
        "    predictions = compute_predictions_logits(\n",
        "        examples,\n",
        "        features,\n",
        "        all_results,\n",
        "        n_best_size,\n",
        "        max_answer_length,\n",
        "        do_lower_case,\n",
        "        output_prediction_file,\n",
        "        output_nbest_file,\n",
        "        output_null_log_odds_file,\n",
        "        False,  # verbose_logging\n",
        "        True,  # version_2_with_negative\n",
        "        null_score_diff_threshold,\n",
        "        tokenizer,\n",
        "    )\n",
        "\n",
        "    return predictions"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "nIQOB8vhpcKs"
      },
      "source": [
        "## 4.0 Run predictions on the Covid QA set\n",
        "\n",
        "Now for the fun part... testing out your model on different inputs. Pretty rudimentary example here. But the possibilities are endless with this function."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "QRrMu7TxTaD1"
      },
      "source": [
        "### 4.1 Reading in the Covid QA set from json"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {
        "id": "LAcb5K9_hVaQ"
      },
      "outputs": [],
      "source": [
        "import pandas as pd\n",
        "\n",
        "def read_test_set():\n",
        "    df = pd.read_json(\"Covid-QA-more-focused.json\")\n",
        "    return df['data']\n",
        "\n",
        "data = read_test_set()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "C7e5yTiNTe7m"
      },
      "source": [
        "### 4.2 Setting up data collection \n",
        "\n",
        "Also making sure we are connected to GPU"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "I50n0Tkz1Ley",
        "outputId": "c1469001-82ea-47c3-dc91-496c6bb3b032"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "/device:GPU:0\n"
          ]
        }
      ],
      "source": [
        "## set up data\n",
        "import time\n",
        "import tensorflow as tf\n",
        "print(tf.test.gpu_device_name())\n",
        "\n",
        "num_right = 0 # giving credit for whenever it comes up with a subset of the string\n",
        "total = 0\n",
        "all_questions = []\n",
        "all_answers = []"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "vpQMa0NFTrfG"
      },
      "source": [
        "### 4.3 Run prediction on each paragraph of Q&A test set"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "metadata": {
        "cellView": "code",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "F-sUrcA5nXTH",
        "outputId": "642ae4b5-bab5-4ee7-a417-d21a0a487c28"
      },
      "outputs": [
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "convert squad examples to features: 100%|██████████| 10/10 [00:04<00:00,  2.39it/s]\n",
            "add example index and unique id: 100%|██████████| 10/10 [00:00<00:00, 18953.02it/s]\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "54.90951585769653\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "convert squad examples to features: 100%|██████████| 2/2 [00:00<00:00,  2.73it/s]\n",
            "add example index and unique id: 100%|██████████| 2/2 [00:00<00:00, 11351.30it/s]\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "12.772334575653076\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "convert squad examples to features: 100%|██████████| 1/1 [00:00<00:00,  4.55it/s]\n",
            "add example index and unique id: 100%|██████████| 1/1 [00:00<00:00, 8848.74it/s]\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "4.255914211273193\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "convert squad examples to features: 100%|██████████| 10/10 [00:02<00:00,  3.47it/s]\n",
            "add example index and unique id: 100%|██████████| 10/10 [00:00<00:00, 18117.94it/s]\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "52.934229373931885\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "convert squad examples to features: 100%|██████████| 8/8 [00:01<00:00,  4.39it/s]\n",
            "add example index and unique id: 100%|██████████| 8/8 [00:00<00:00, 2668.34it/s]\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "34.4197199344635\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "convert squad examples to features: 100%|██████████| 5/5 [00:01<00:00,  3.19it/s]\n",
            "add example index and unique id: 100%|██████████| 5/5 [00:00<00:00, 22239.15it/s]\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "28.214336156845093\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "convert squad examples to features: 100%|██████████| 4/4 [00:00<00:00, 20.95it/s]\n",
            "add example index and unique id: 100%|██████████| 4/4 [00:00<00:00, 17829.13it/s]\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "4.168558597564697\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "convert squad examples to features: 100%|██████████| 11/11 [00:01<00:00,  5.51it/s]\n",
            "add example index and unique id: 100%|██████████| 11/11 [00:00<00:00, 34533.94it/s]\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "40.80004405975342\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "convert squad examples to features: 100%|██████████| 8/8 [00:03<00:00,  2.57it/s]\n",
            "add example index and unique id: 100%|██████████| 8/8 [00:00<00:00, 20984.64it/s]\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "54.11480212211609\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "convert squad examples to features: 100%|██████████| 5/5 [00:00<00:00,  5.85it/s]\n",
            "add example index and unique id: 100%|██████████| 5/5 [00:00<00:00, 25085.55it/s]\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "18.51632595062256\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "convert squad examples to features: 100%|██████████| 29/29 [00:08<00:00,  3.47it/s]\n",
            "add example index and unique id: 100%|██████████| 29/29 [00:00<00:00, 33224.48it/s]\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "153.47424936294556\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "convert squad examples to features: 100%|██████████| 4/4 [00:00<00:00, 18.33it/s]\n",
            "add example index and unique id: 100%|██████████| 4/4 [00:00<00:00, 25536.10it/s]\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "5.275418758392334\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "convert squad examples to features: 100%|██████████| 1/1 [00:00<00:00, 10.88it/s]\n",
            "add example index and unique id: 100%|██████████| 1/1 [00:00<00:00, 7667.83it/s]\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "2.188803195953369\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "convert squad examples to features: 100%|██████████| 27/27 [00:02<00:00, 12.04it/s]\n",
            "add example index and unique id: 100%|██████████| 27/27 [00:00<00:00, 8832.87it/s]\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "53.50041651725769\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "convert squad examples to features: 100%|██████████| 20/20 [00:04<00:00,  4.56it/s]\n",
            "add example index and unique id: 100%|██████████| 20/20 [00:00<00:00, 35084.10it/s]\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "80.23439502716064\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "convert squad examples to features: 100%|██████████| 1/1 [00:00<00:00, 21.56it/s]\n",
            "add example index and unique id: 100%|██████████| 1/1 [00:00<00:00, 10754.63it/s]\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "1.0264718532562256\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "convert squad examples to features: 100%|██████████| 30/30 [00:05<00:00,  5.20it/s]\n",
            "add example index and unique id: 100%|██████████| 30/30 [00:00<00:00, 40708.22it/s]\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "115.32675504684448\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "convert squad examples to features: 100%|██████████| 59/59 [00:36<00:00,  1.64it/s]\n",
            "add example index and unique id: 100%|██████████| 59/59 [00:00<00:00, 19415.03it/s]\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "546.1623101234436\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "convert squad examples to features: 100%|██████████| 15/15 [00:06<00:00,  2.20it/s]\n",
            "add example index and unique id: 100%|██████████| 15/15 [00:00<00:00, 19679.25it/s]\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "118.43807315826416\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "convert squad examples to features: 100%|██████████| 13/13 [00:01<00:00,  6.52it/s]\n",
            "add example index and unique id: 100%|██████████| 13/13 [00:00<00:00, 39799.96it/s]\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "39.12144756317139\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "convert squad examples to features: 100%|██████████| 5/5 [00:01<00:00,  4.49it/s]\n",
            "add example index and unique id: 100%|██████████| 5/5 [00:00<00:00, 12771.94it/s]\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "21.57089853286743\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "convert squad examples to features: 100%|██████████| 119/119 [03:40<00:00,  1.86s/it]\n",
            "add example index and unique id: 100%|██████████| 119/119 [00:00<00:00, 9357.02it/s]\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "2295.0699808597565\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "convert squad examples to features: 100%|██████████| 23/23 [00:10<00:00,  2.23it/s]\n",
            "add example index and unique id: 100%|██████████| 23/23 [00:00<00:00, 19878.22it/s]\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "166.01409888267517\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "convert squad examples to features: 100%|██████████| 1/1 [00:00<00:00, 15.13it/s]\n",
            "add example index and unique id: 100%|██████████| 1/1 [00:00<00:00, 7206.71it/s]\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "1.3852620124816895\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "convert squad examples to features: 100%|██████████| 10/10 [00:01<00:00,  6.03it/s]\n",
            "add example index and unique id: 100%|██████████| 10/10 [00:00<00:00, 38692.84it/s]\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "32.883503437042236\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "convert squad examples to features: 100%|██████████| 1/1 [00:01<00:00,  1.20s/it]\n",
            "add example index and unique id: 100%|██████████| 1/1 [00:00<00:00, 5426.01it/s]\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "14.458309412002563\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "convert squad examples to features: 100%|██████████| 24/24 [00:06<00:00,  3.80it/s]\n",
            "add example index and unique id: 100%|██████████| 24/24 [00:00<00:00, 29237.09it/s]\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "116.81744837760925\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "convert squad examples to features: 100%|██████████| 2/2 [00:01<00:00,  1.10it/s]\n",
            "add example index and unique id: 100%|██████████| 2/2 [00:00<00:00, 6379.17it/s]\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "23.621113300323486\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "convert squad examples to features: 100%|██████████| 9/9 [00:00<00:00, 12.38it/s]\n",
            "add example index and unique id: 100%|██████████| 9/9 [00:00<00:00, 50064.64it/s]\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "15.521681785583496\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "convert squad examples to features: 100%|██████████| 3/3 [00:00<00:00, 12.93it/s]\n",
            "add example index and unique id: 100%|██████████| 3/3 [00:00<00:00, 25890.77it/s]\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "5.335078716278076\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "convert squad examples to features: 100%|██████████| 21/21 [00:03<00:00,  6.62it/s]\n",
            "add example index and unique id: 100%|██████████| 21/21 [00:00<00:00, 27997.58it/s]\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "63.05487585067749\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "convert squad examples to features: 100%|██████████| 125/125 [01:22<00:00,  1.52it/s]\n",
            "add example index and unique id: 100%|██████████| 125/125 [00:00<00:00, 17401.44it/s]\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "1214.2180511951447\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "convert squad examples to features: 100%|██████████| 56/56 [01:35<00:00,  1.70s/it]\n",
            "add example index and unique id: 100%|██████████| 56/56 [00:00<00:00, 8231.33it/s]\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "1032.862919330597\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "convert squad examples to features: 100%|██████████| 6/6 [00:00<00:00,  7.60it/s]\n",
            "add example index and unique id: 100%|██████████| 6/6 [00:00<00:00, 24361.88it/s]\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "17.240938425064087\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "convert squad examples to features: 100%|██████████| 53/53 [00:09<00:00,  5.58it/s]\n",
            "add example index and unique id: 100%|██████████| 53/53 [00:00<00:00, 39247.55it/s]\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "188.98384714126587\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "convert squad examples to features: 100%|██████████| 16/16 [00:03<00:00,  5.02it/s]\n",
            "add example index and unique id: 100%|██████████| 16/16 [00:00<00:00, 30066.70it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "62.46181917190552\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "convert squad examples to features: 100%|██████████| 46/46 [00:10<00:00,  4.58it/s]\n",
            "add example index and unique id: 100%|██████████| 46/46 [00:00<00:00, 36645.39it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "209.23027205467224\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "convert squad examples to features: 100%|██████████| 1/1 [00:01<00:00,  1.17s/it]\n",
            "add example index and unique id: 100%|██████████| 1/1 [00:00<00:00, 4529.49it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "14.35268259048462\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "convert squad examples to features: 100%|██████████| 2/2 [00:00<00:00, 36.94it/s]\n",
            "add example index and unique id: 100%|██████████| 2/2 [00:00<00:00, 17623.13it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "1.337998628616333\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "convert squad examples to features: 100%|██████████| 2/2 [00:00<00:00,  8.81it/s]\n",
            "add example index and unique id: 100%|██████████| 2/2 [00:00<00:00, 11554.56it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "5.059569835662842\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "convert squad examples to features: 100%|██████████| 14/14 [00:03<00:00,  4.36it/s]\n",
            "add example index and unique id: 100%|██████████| 14/14 [00:00<00:00, 25541.65it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "60.33205246925354\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "convert squad examples to features: 100%|██████████| 26/26 [00:01<00:00, 20.28it/s]\n",
            "add example index and unique id: 100%|██████████| 26/26 [00:00<00:00, 89167.54it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "29.684961795806885\n",
            "total time:  -7011.369504451752\n"
          ]
        }
      ],
      "source": [
        "total_start = time.time()\n",
        "for item in data:\n",
        "    start = time.time()\n",
        "\n",
        "    paragraph = item[\"paragraphs\"][0]\n",
        "    \n",
        "    questions_with_answers = paragraph[\"qas\"]\n",
        "    context = paragraph[\"context\"]\n",
        "    questions = []\n",
        "    answers = []\n",
        "\n",
        "    for qa in questions_with_answers:\n",
        "        questions.append(qa[\"question\"])\n",
        "        answers.append(qa[\"answers\"])\n",
        "\n",
        "    predictions = run_prediction(questions, context)\n",
        "    idx = 0\n",
        "    for key in predictions.keys():\n",
        "      pos_answers = answers[idx]\n",
        "      correct = False\n",
        "\n",
        "      all_questions = all_questions + questions\n",
        "      all_answers.append({'model_answer': predictions[key], 'valid_answers': pos_answers})\n",
        "      for answer in pos_answers:\n",
        "        answer_text = answer['text']\n",
        "        correct = correct or (predictions[key] in answer_text)\n",
        "      if correct:\n",
        "        num_right += 1\n",
        "      end = time.time()\n",
        "\n",
        "      total += 1\n",
        "      idx += 1\n",
        "    end = time.time()\n",
        "    print(end - start)\n",
        "\n",
        "print(\"total time: \", total_start - time.time())"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "PVxpvDFeT0Cr"
      },
      "source": [
        "### 4.4 Export data to json for easy reuse"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 8,
      "metadata": {
        "id": "16cD8mbb173f",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "8bcac8c8-94f2-4590-ecdb-75c7154f233e"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "num-right: 573\n",
            "total: 828\n"
          ]
        }
      ],
      "source": [
        "import json\n",
        "\n",
        "print(\"num-right:\", num_right)\n",
        "print(\"total:\", total)\n",
        "# print(all_questions)\n",
        "# print(all_answers)\n",
        "with open(\"answers.json\", \"w\") as f:\n",
        "    json.dump(all_answers, f)\n",
        "\n",
        "with open(\"questions.json\", \"w\") as g:\n",
        "    json.dump(all_questions, g)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "-lONCnMmoVCC"
      },
      "source": [
        "### 4.5 Evaluate the model\n",
        "We will evalue the model using https://huggingface.co/spaces/evaluate-metric/bertscore \n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "A5I7BiS1o2E3"
      },
      "source": [
        "#### 4.5.1 Imports"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 9,
      "metadata": {
        "id": "S0Xk9bzroUQT",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000,
          "referenced_widgets": [
            "2906947dbb0445328c2facc291c9678a",
            "3d8b3a25bd0841efa4407409f787d4ce",
            "ebbeb5a4d17640188f5dea555c7a25b7",
            "0dc5d2ff49ec403f8d08a600b0aa7ab4",
            "02027cd601ba47dfad201edaa9beeda5",
            "4b0f54d1534d4d8c9012cdc079dcd161",
            "fda115d9eb9c45e198da067396d4b56c",
            "3c5ccbd8e3e84919954767fe3d9cea3f",
            "449f5b23d8654c58b0080da5feca8ec4",
            "a55a70987b2244dea1278402348a821a",
            "1d6aad3e74e14a61b3d2a699618b592a"
          ]
        },
        "outputId": "26640899-4ae2-47fe-e875-5a5e5ad5dacc"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Collecting evaluate\n",
            "  Downloading evaluate-0.2.2-py3-none-any.whl (69 kB)\n",
            "\u001b[K     |████████████████████████████████| 69 kB 3.1 MB/s \n",
            "\u001b[?25hRequirement already satisfied: dill in /usr/local/lib/python3.7/dist-packages (from evaluate) (0.3.5.1)\n",
            "Requirement already satisfied: numpy>=1.17 in /usr/local/lib/python3.7/dist-packages (from evaluate) (1.21.6)\n",
            "Requirement already satisfied: packaging in /usr/local/lib/python3.7/dist-packages (from evaluate) (21.3)\n",
            "Requirement already satisfied: requests>=2.19.0 in /usr/local/lib/python3.7/dist-packages (from evaluate) (2.23.0)\n",
            "Collecting datasets>=2.0.0\n",
            "  Downloading datasets-2.4.0-py3-none-any.whl (365 kB)\n",
            "\u001b[K     |████████████████████████████████| 365 kB 8.4 MB/s \n",
            "\u001b[?25hRequirement already satisfied: pandas in /usr/local/lib/python3.7/dist-packages (from evaluate) (1.3.5)\n",
            "Requirement already satisfied: tqdm>=4.62.1 in /usr/local/lib/python3.7/dist-packages (from evaluate) (4.64.0)\n",
            "Collecting xxhash\n",
            "  Downloading xxhash-3.0.0-cp37-cp37m-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (212 kB)\n",
            "\u001b[K     |████████████████████████████████| 212 kB 50.6 MB/s \n",
            "\u001b[?25hCollecting multiprocess\n",
            "  Downloading multiprocess-0.70.13-py37-none-any.whl (115 kB)\n",
            "\u001b[K     |████████████████████████████████| 115 kB 72.5 MB/s \n",
            "\u001b[?25hCollecting huggingface-hub>=0.7.0\n",
            "  Downloading huggingface_hub-0.8.1-py3-none-any.whl (101 kB)\n",
            "\u001b[K     |████████████████████████████████| 101 kB 13.4 MB/s \n",
            "\u001b[?25hCollecting responses<0.19\n",
            "  Downloading responses-0.18.0-py3-none-any.whl (38 kB)\n",
            "Requirement already satisfied: importlib-metadata in /usr/local/lib/python3.7/dist-packages (from evaluate) (4.12.0)\n",
            "Collecting fsspec[http]>=2021.05.0\n",
            "  Downloading fsspec-2022.7.1-py3-none-any.whl (141 kB)\n",
            "\u001b[K     |████████████████████████████████| 141 kB 73.6 MB/s \n",
            "\u001b[?25hRequirement already satisfied: pyarrow>=6.0.0 in /usr/local/lib/python3.7/dist-packages (from datasets>=2.0.0->evaluate) (6.0.1)\n",
            "Requirement already satisfied: aiohttp in /usr/local/lib/python3.7/dist-packages (from datasets>=2.0.0->evaluate) (3.8.1)\n",
            "Collecting pyyaml>=5.1\n",
            "  Downloading PyYAML-6.0-cp37-cp37m-manylinux_2_5_x86_64.manylinux1_x86_64.manylinux_2_12_x86_64.manylinux2010_x86_64.whl (596 kB)\n",
            "\u001b[K     |████████████████████████████████| 596 kB 73.5 MB/s \n",
            "\u001b[?25hRequirement already satisfied: typing-extensions>=3.7.4.3 in /usr/local/lib/python3.7/dist-packages (from huggingface-hub>=0.7.0->evaluate) (4.1.1)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.7/dist-packages (from huggingface-hub>=0.7.0->evaluate) (3.7.1)\n",
            "Requirement already satisfied: pyparsing!=3.0.5,>=2.0.2 in /usr/local/lib/python3.7/dist-packages (from packaging->evaluate) (3.0.9)\n",
            "Requirement already satisfied: chardet<4,>=3.0.2 in /usr/local/lib/python3.7/dist-packages (from requests>=2.19.0->evaluate) (3.0.4)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.7/dist-packages (from requests>=2.19.0->evaluate) (2022.6.15)\n",
            "Requirement already satisfied: urllib3!=1.25.0,!=1.25.1,<1.26,>=1.21.1 in /usr/local/lib/python3.7/dist-packages (from requests>=2.19.0->evaluate) (1.25.11)\n",
            "Requirement already satisfied: idna<3,>=2.5 in /usr/local/lib/python3.7/dist-packages (from requests>=2.19.0->evaluate) (2.10)\n",
            "Requirement already satisfied: frozenlist>=1.1.1 in /usr/local/lib/python3.7/dist-packages (from aiohttp->datasets>=2.0.0->evaluate) (1.3.1)\n",
            "Requirement already satisfied: attrs>=17.3.0 in /usr/local/lib/python3.7/dist-packages (from aiohttp->datasets>=2.0.0->evaluate) (22.1.0)\n",
            "Requirement already satisfied: async-timeout<5.0,>=4.0.0a3 in /usr/local/lib/python3.7/dist-packages (from aiohttp->datasets>=2.0.0->evaluate) (4.0.2)\n",
            "Requirement already satisfied: yarl<2.0,>=1.0 in /usr/local/lib/python3.7/dist-packages (from aiohttp->datasets>=2.0.0->evaluate) (1.8.1)\n",
            "Requirement already satisfied: asynctest==0.13.0 in /usr/local/lib/python3.7/dist-packages (from aiohttp->datasets>=2.0.0->evaluate) (0.13.0)\n",
            "Requirement already satisfied: charset-normalizer<3.0,>=2.0 in /usr/local/lib/python3.7/dist-packages (from aiohttp->datasets>=2.0.0->evaluate) (2.1.0)\n",
            "Requirement already satisfied: multidict<7.0,>=4.5 in /usr/local/lib/python3.7/dist-packages (from aiohttp->datasets>=2.0.0->evaluate) (6.0.2)\n",
            "Requirement already satisfied: aiosignal>=1.1.2 in /usr/local/lib/python3.7/dist-packages (from aiohttp->datasets>=2.0.0->evaluate) (1.2.0)\n",
            "Requirement already satisfied: zipp>=0.5 in /usr/local/lib/python3.7/dist-packages (from importlib-metadata->evaluate) (3.8.1)\n",
            "Requirement already satisfied: python-dateutil>=2.7.3 in /usr/local/lib/python3.7/dist-packages (from pandas->evaluate) (2.8.2)\n",
            "Requirement already satisfied: pytz>=2017.3 in /usr/local/lib/python3.7/dist-packages (from pandas->evaluate) (2022.1)\n",
            "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.7/dist-packages (from python-dateutil>=2.7.3->pandas->evaluate) (1.15.0)\n",
            "Installing collected packages: pyyaml, fsspec, xxhash, responses, multiprocess, huggingface-hub, datasets, evaluate\n",
            "  Attempting uninstall: pyyaml\n",
            "    Found existing installation: PyYAML 3.13\n",
            "    Uninstalling PyYAML-3.13:\n",
            "      Successfully uninstalled PyYAML-3.13\n",
            "Successfully installed datasets-2.4.0 evaluate-0.2.2 fsspec-2022.7.1 huggingface-hub-0.8.1 multiprocess-0.70.13 pyyaml-6.0 responses-0.18.0 xxhash-3.0.0\n",
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Collecting bert_score\n",
            "  Downloading bert_score-0.3.11-py3-none-any.whl (60 kB)\n",
            "\u001b[K     |████████████████████████████████| 60 kB 2.4 MB/s \n",
            "\u001b[?25hRequirement already satisfied: requests in /usr/local/lib/python3.7/dist-packages (from bert_score) (2.23.0)\n",
            "Requirement already satisfied: tqdm>=4.31.1 in /usr/local/lib/python3.7/dist-packages (from bert_score) (4.64.0)\n",
            "Requirement already satisfied: pandas>=1.0.1 in /usr/local/lib/python3.7/dist-packages (from bert_score) (1.3.5)\n",
            "Requirement already satisfied: packaging>=20.9 in /usr/local/lib/python3.7/dist-packages (from bert_score) (21.3)\n",
            "Requirement already satisfied: torch>=1.0.0 in /usr/local/lib/python3.7/dist-packages (from bert_score) (1.12.1+cu113)\n",
            "Collecting transformers>=3.0.0numpy\n",
            "  Downloading transformers-4.21.1-py3-none-any.whl (4.7 MB)\n",
            "\u001b[K     |████████████████████████████████| 4.7 MB 6.7 MB/s \n",
            "\u001b[?25hRequirement already satisfied: matplotlib in /usr/local/lib/python3.7/dist-packages (from bert_score) (3.2.2)\n",
            "Requirement already satisfied: pyparsing!=3.0.5,>=2.0.2 in /usr/local/lib/python3.7/dist-packages (from packaging>=20.9->bert_score) (3.0.9)\n",
            "Requirement already satisfied: python-dateutil>=2.7.3 in /usr/local/lib/python3.7/dist-packages (from pandas>=1.0.1->bert_score) (2.8.2)\n",
            "Requirement already satisfied: numpy>=1.17.3 in /usr/local/lib/python3.7/dist-packages (from pandas>=1.0.1->bert_score) (1.21.6)\n",
            "Requirement already satisfied: pytz>=2017.3 in /usr/local/lib/python3.7/dist-packages (from pandas>=1.0.1->bert_score) (2022.1)\n",
            "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.7/dist-packages (from python-dateutil>=2.7.3->pandas>=1.0.1->bert_score) (1.15.0)\n",
            "Requirement already satisfied: typing-extensions in /usr/local/lib/python3.7/dist-packages (from torch>=1.0.0->bert_score) (4.1.1)\n",
            "Requirement already satisfied: importlib-metadata in /usr/local/lib/python3.7/dist-packages (from transformers>=3.0.0numpy->bert_score) (4.12.0)\n",
            "Requirement already satisfied: regex!=2019.12.17 in /usr/local/lib/python3.7/dist-packages (from transformers>=3.0.0numpy->bert_score) (2022.6.2)\n",
            "Requirement already satisfied: huggingface-hub<1.0,>=0.1.0 in /usr/local/lib/python3.7/dist-packages (from transformers>=3.0.0numpy->bert_score) (0.8.1)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.7/dist-packages (from transformers>=3.0.0numpy->bert_score) (3.7.1)\n",
            "Collecting tokenizers!=0.11.3,<0.13,>=0.11.1\n",
            "  Downloading tokenizers-0.12.1-cp37-cp37m-manylinux_2_12_x86_64.manylinux2010_x86_64.whl (6.6 MB)\n",
            "\u001b[K     |████████████████████████████████| 6.6 MB 50.4 MB/s \n",
            "\u001b[?25hRequirement already satisfied: pyyaml>=5.1 in /usr/local/lib/python3.7/dist-packages (from transformers>=3.0.0numpy->bert_score) (6.0)\n",
            "Requirement already satisfied: zipp>=0.5 in /usr/local/lib/python3.7/dist-packages (from importlib-metadata->transformers>=3.0.0numpy->bert_score) (3.8.1)\n",
            "Requirement already satisfied: kiwisolver>=1.0.1 in /usr/local/lib/python3.7/dist-packages (from matplotlib->bert_score) (1.4.4)\n",
            "Requirement already satisfied: cycler>=0.10 in /usr/local/lib/python3.7/dist-packages (from matplotlib->bert_score) (0.11.0)\n",
            "Requirement already satisfied: chardet<4,>=3.0.2 in /usr/local/lib/python3.7/dist-packages (from requests->bert_score) (3.0.4)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.7/dist-packages (from requests->bert_score) (2022.6.15)\n",
            "Requirement already satisfied: urllib3!=1.25.0,!=1.25.1,<1.26,>=1.21.1 in /usr/local/lib/python3.7/dist-packages (from requests->bert_score) (1.25.11)\n",
            "Requirement already satisfied: idna<3,>=2.5 in /usr/local/lib/python3.7/dist-packages (from requests->bert_score) (2.10)\n",
            "Installing collected packages: tokenizers, transformers, bert-score\n",
            "  Attempting uninstall: tokenizers\n",
            "    Found existing installation: tokenizers 0.0.11\n",
            "    Uninstalling tokenizers-0.0.11:\n",
            "      Successfully uninstalled tokenizers-0.0.11\n",
            "  Attempting uninstall: transformers\n",
            "    Found existing installation: transformers 2.3.0\n",
            "    Uninstalling transformers-2.3.0:\n",
            "      Successfully uninstalled transformers-2.3.0\n",
            "Successfully installed bert-score-0.3.11 tokenizers-0.12.1 transformers-4.21.1\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "application/vnd.colab-display-data+json": {
              "pip_warning": {
                "packages": [
                  "tokenizers",
                  "transformers"
                ]
              }
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "Downloading builder script:   0%|          | 0.00/7.79k [00:00<?, ?B/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "2906947dbb0445328c2facc291c9678a"
            }
          },
          "metadata": {}
        }
      ],
      "source": [
        "## Imports and setup\n",
        "!pip3 install evaluate\n",
        "!pip3 install bert_score\n",
        "from evaluate import load\n",
        "import pandas as pd\n",
        "\n",
        "bertscore = load(\"bertscore\")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "mFQUXmsGpAPY"
      },
      "source": [
        "#### 4.5.2 Loading the data\n",
        "\n",
        "We saved the data to a json so lets load it in"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "oKxrdxEWpoIN"
      },
      "outputs": [],
      "source": [
        "\n",
        "model_answers = pd.read_json(\"model_answers.json\")\n",
        "\n",
        "answers = []\n",
        "references = []\n",
        "\n",
        "for answer, valid in zip(model_answers[\"model_answer\"], model_answers[\"valid_answers\"]):\n",
        "  answers.append(answer)\n",
        "  references.append(valid[0][\"text\"])\n",
        "    "
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ByjMwni7rm9r"
      },
      "source": [
        "#### 4.5.3 Calculate the metrics"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "BNKyBB6mrrE_"
      },
      "outputs": [],
      "source": [
        "results = bertscore.compute(predictions=answers, references=references, lang=\"en\")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "tlIHEKE9uXVk"
      },
      "outputs": [],
      "source": [
        "\n",
        "total_precision = 0\n",
        "total_recall = 0\n",
        "total_f1 = 0\n",
        "\n",
        "count = 0\n",
        "\n",
        "for prec, recall, f1 in zip(results[\"precision\"], results[\"recall\"], results[\"f1\"]):\n",
        "  if prec != 0:\n",
        "    count += 1\n",
        "    total_precision += prec\n",
        "    total_recall += recall\n",
        "    total_f1 += f1\n",
        "\n",
        "precision = total_precision / count\n",
        "recall = total_recall / count\n",
        "f1 = total_f1 / count\n",
        "\n",
        "print(\"Precision: \",precision)\n",
        "print(\"Recall: \", recall)\n",
        "print(\"F1: \", f1)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Y1C_EjEWnExZ"
      },
      "source": [
        "## 5.0 So How does it Perform for questions using the CDCs covid advice website?"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Yu4pOCenoM3w"
      },
      "outputs": [],
      "source": [
        "cdc_guidance = \"IF YOU Were exposed to COVID-19 and are NOT up to date on COVID-19 vaccinations Quarantine for at least 5 days Stay home Stay home and quarantine for at least 5 full days. Wear a well-fitting mask if you must be around others in your home. Do not travel. Get tested Even if you don’t develop symptoms, get tested at least 5 days after you last had close contact with someone with COVID-19. After quarantine Watch for symptoms Watch for symptoms until 10 days after you last had close contact with someone with COVID-19. Avoid travel It is best to avoid travel until a full 10 days after you last had close contact with someone with COVID-19. If you develop symptoms Isolate immediately and get tested. Continue to stay home until you know the results. Wear a well-fitting mask around others. Take precautions until day 10 Wear a well-fitting mask Wear a well-fitting mask for 10 full days any time you are around others inside your home or in public. Do not go to places where you are unable to wear a well-fitting mask. If you must travel during days 6-10, take precautions. Avoid being around people who are more likely to get very sick from COVID-19. IF YOU Were exposed to COVID-19 and are up to date on COVID-19 vaccinations No quarantine You do not need to stay home unless you develop symptoms. Get tested Even if you don’t develop symptoms, get tested at least 5 days after you last had close contact with someone with COVID-19. Watch for symptoms Watch for symptoms until 10 days after you last had close contact with someone with COVID-19. If you develop symptoms Isolate immediately and get tested. Continue to stay home until you know the results. Wear a well-fitting mask around others. Take precautions until day 10 Wear a well-fitting mask Wear a well-fitting mask for 10 full days any time you are around others inside your home or in public. Do not go to places where you are unable to wear a well-fitting mask. Take precautions if traveling Avoid being around people who are more likely to get very sick from COVID-19. IF YOU were exposed to COVID-19 and had confirmed COVID-19 within the past 90 days (you tested positive using a viral test) No quarantine You do not need to stay home unless you develop symptoms. Watch for symptoms Watch for symptoms until 10 days after you last had close contact with someone with COVID-19.  If you develop symptoms Isolate immediately and get tested. Continue to stay home until you know the results. Wear a well-fitting mask around others. Take precautions until day 10 Wear a well-fitting mask Wear a well-fitting mask for 10 full days any time you are around others inside your home or in public. Do not go to places where you are unable to wear a well-fitting mask. Take precautions if traveling Avoid being around people who are more likely to get very sick from COVID-19. Calculating Isolation Day 0 is your first day of symptoms or a positive viral test. Day 1 is the first full day after your symptoms developed or your test specimen was collected. If you have COVID-19 or have symptoms, isolate for at least 5 days. IF YOU Tested positive for COVID-19 or have symptoms, regardless of vaccination status Stay home for at least 5 days Stay home for 5 days and isolate from others in your home. Wear a well-fitting mask if you must be around others in your home. Do not travel. Ending isolation if you had symptoms End isolation after 5 full days if you are fever-free for 24 hours (without the use of fever-reducing medication) and your symptoms are improving. Ending isolation if you did NOT have symptoms End isolation after at least 5 full days after your positive test. If you got very sick from COVID-19 or have a weakened immune system You should isolate for at least 10 days. Consult your doctor before ending isolation. Take precautions until day 10 Wear a well-fitting mask  Wear a well-fitting mask for 10 full days any time you are around others inside your home or in public. Do not go to places where you are unable to wear a mask. Do not travel Do not travel until a full 10 days after your symptoms started or the date your positive test was taken if you had no symptoms. Avoid being around people who are more likely to get very sick from COVID-19.  DEFINITIONS Exposure Contact with someone infected with SARS-CoV-2, the virus that causes COVID-19, in a way that increases the likelihood of getting infected with the virus. Close Contact A close contact is someone who was less than 6 feet away from an infected person (laboratory-confirmed or a clinical diagnosis) for a cumulative total of 15 minutes or more over a 24-hour period. For example, three individual 5-minute exposures for a total of 15 minutes. People who are exposed to someone with COVID-19 after they completed at least 5 days of isolation are not considered close contacts. Quarantine Quarantine is a strategy used to prevent transmission of COVID-19 by keeping people who have been in close contact with someone with COVID-19 apart from others. Who does not need to quarantine? If you had close contact with someone with COVID-19 and you are in one of the following groups, you do not need to quarantine. You are up to date with your COVID-19 vaccines. You had confirmed COVID-19 within the last 90 days (meaning you tested positive using a viral test). If you are up to date with COVID-19 vaccines, you should wear a well-fitting mask around others for 10 days from the date of your last close contact with someone with COVID-19 (the date of last close contact is considered day 0). Get tested at least 5 days after you last had close contact with someone with COVID-19. If you test positive or develop COVID-19 symptoms, isolate from other people and follow recommendations in the Isolation section below. If you tested positive for COVID-19 with a viral test within the previous 90 days and subsequently recovered and remain without COVID-19 symptoms, you do not need to quarantine or get tested after close contact. You should wear a well-fitting mask around others for 10 days from the date of your last close contact with someone with COVID-19 (the date of last close contact is considered day 0). If you have COVID-19 symptoms, get tested and isolate from other people and follow recommendations in the Isolation section below. Who should quarantine? If you come into close contact with someone with COVID-19, you should quarantine if you are not up to date on COVID-19 vaccines. This includes people who are not vaccinated. What to do for quarantine Stay home and away from other people for at least 5 days (day 0 through day 5) after your last contact with a person who has COVID-19. The date of your exposure is considered day 0. Wear a well-fitting mask when around others at home, if possible. For 10 days after your last close contact with someone with COVID-19, watch for fever (100.4◦F or greater), cough, shortness of breath, or other COVID-19 symptoms. If you develop symptoms, get tested immediately and isolate until you receive your test results. If you test positive, follow isolation recommendations. If you do not develop symptoms, get tested at least 5 days after you last had close contact with someone with COVID-19. If you test negative, you can leave your home, but continue to wear a well-fitting mask when around others at home and in public until 10 days after your last close contact with someone with COVID-19. If you test positive, you should isolate for at least 5 days from the date of your positive test (if you do not have symptoms). If you do develop COVID-19 symptoms, isolate for at least 5 days from the date your symptoms began (the date the symptoms started is day 0). Follow recommendations in the isolation section below. If you are unable to get a test 5 days after last close contact with someone with COVID-19, you can leave your home after day 5 if you have been without COVID-19 symptoms throughout the 5-day period. Wear a well-fitting mask for 10 days after your date of last close contact when around others at home and in public. Avoid people who are have weakened immune systems or are more likely to get very sick from COVID-19, and nursing homes and other high-risk settings, until after at least 10 days. If possible, stay away from people you live with, especially people who are at higher risk for getting very sick from COVID-19, as well as others outside your home throughout the full 10 days after your last close contact with someone with COVID-19. If you are unable to quarantine, you should wear a well-fitting mask for 10 days when around others at home and in public. If you are unable to wear a mask when around others, you should continue to quarantine for 10 days. Avoid people who have weakened immune systems or are more likely to get very sick from COVID-19, and nursing homes and other high-risk settings, until after at least 10 days. See additional information about travel. Do not go to places where you are unable to wear a mask, such as restaurants and some gyms, and avoid eating around others at home and at work until after 10 days after your last close contact with someone with COVID-19. After quarantine Watch for symptoms until 10 days after your last close contact with someone with COVID-19. If you have symptoms, isolate immediately and get tested. Quarantine in high-risk congregate settings In certain congregate settings that have high risk of secondary transmission (such as correctional and detention facilities, homeless shelters, or cruise ships), CDC recommends a 10-day quarantine for residents, regardless of vaccination and booster status. During periods of critical staffing shortages, facilities may consider shortening the quarantine period for staff to ensure continuity of operations. Decisions to shorten quarantine in these settings should be made in consultation with state, local, tribal, or territorial health departments and should take into consideration the context and characteristics of the facility. CDC’s setting-specific guidance provides additional recommendations for these settings. Isolation Isolation is used to separate people with confirmed or suspected COVID-19 from those without COVID-19. People who are in isolation should stay home until it’s safe for them to be around others. At home, anyone sick or infected should separate from others, or wear a well-fitting mask when they need to be around others. People in isolation should stay in a specific “sick room” or area and use a separate bathroom if available. Everyone who has presumed or confirmed COVID-19 should stay home and isolate from other people for at least 5 full days (day 0 is the first day of symptoms or the date of the day of the positive viral test for asymptomatic persons). They should wear a mask when around others at home and in public for an additional 5 days. People who are confirmed to have COVID-19 or are showing symptoms of COVID-19 need to isolate regardless of their vaccination status. This includes: People who have a positive viral test for COVID-19, regardless of whether or not they have symptoms. People with symptoms of COVID-19, including people who are awaiting test results or have not been tested. People with symptoms should isolate even if they do not know if they have been in close contact with someone with COVID-19. What to do for isolation Monitor your symptoms. If you have an emergency warning sign (including trouble breathing), seek emergency medical care immediately. Stay in a separate room from other household members, if possible. Use a separate bathroom, if possible. Take steps to improve ventilation at home, if possible. Avoid contact with other members of the household and pets. Don’t share personal household items, like cups, towels, and utensils. Wear a well-fitting mask when you need to be around other people. Learn more about what to do if you are sick and how to notify your contacts. Top of Page Ending isolation for people who had COVID-19 and had symptoms If you had COVID-19 and had symptoms, isolate for at least 5 days. To calculate your 5-day isolation period, day 0 is your first day of symptoms. Day 1 is the first full day after your symptoms developed. You can leave isolation after 5 full days. You can end isolation after 5 full days if you are fever-free for 24 hours without the use of fever-reducing medication and your other symptoms have improved (Loss of taste and smell may persist for weeks or months after recovery and need not delay the end of isolation ). You should continue to wear a well-fitting mask around others at home and in public for 5 additional days (day 6 through day 10) after the end of your 5-day isolation period. If you are unable to wear a mask when around others, you should continue to isolate for a full 10 days. Avoid people who have weakened immune systems or are more likely to get very sick from COVID-19, and nursing homes and other high-risk settings, until after at least 10 days. If you continue to have fever or your other symptoms have not improved after 5 days of isolation, you should wait to end your isolation until you are fever-free for 24 hours without the use of fever-reducing medication and your other symptoms have improved. Continue to wear a well-fitting mask through day 10. Contact your healthcare provider if you have questions. See additional information about travel. Do not go to places where you are unable to wear a mask, such as restaurants and some gyms, and avoid eating around others at home and at work until a full 10 days after your first day of symptoms. If an individual has access to a test and wants to test, the best approach is to use an antigen test1 towards the end of the 5-day isolation period. Collect the test sample only if you are fever-free for 24 hours without the use of fever-reducing medication and your other symptoms have improved (loss of taste and smell may persist for weeks or months after recovery and need not delay the end of isolation). If your test result is positive, you should continue to isolate until day 10. If your test result is negative, you can end isolation, but continue to wear a well-fitting mask around others at home and in public until day 10. Follow additional recommendations for masking and avoiding travel as described above. 1As noted in the labeling for authorized over-the counter antigen tests:   Negative results should be treated as presumptive. Negative results do not rule out SARS-CoV-2 infection and should not be used as the sole basis for treatment or patient management decisions, including infection control decisions. To improve results, antigen tests should be used twice over a three-day period with at least 24 hours and no more than 48 hours between tests. Note that these recommendations on ending isolation do not apply to people who are moderately ill or very sick from COVID-19 or have weakened immune systems. See section below for recommendations for when to end isolation for these groups. Ending isolation for people who tested positive for COVID-19 but had no symptoms If you test positive for COVID-19 and never develop symptoms, isolate for at least 5 days. Day 0 is the day of your positive viral test (based on the date you were tested) and day 1 is the first full day after the specimen was collected for your positive test. You can leave isolation after 5 full days. If you continue to have no symptoms, you can end isolation after at least 5 days. You should continue to wear a well-fitting mask around others at home and in public until day 10 (day 6 through day 10). If you are unable to wear a mask when around others, you should continue to isolate for 10 days. Avoid people who have weakened immune systems or are more likely to get very sick from COVID-19, and nursing homes and other high-risk settings, until after at least 10 days. If you develop symptoms after testing positive, your 5-day isolation period should start over. Day 0 is your first day of symptoms. Follow the recommendations above for ending isolation for people who had COVID-19 and had symptoms. See additional information about travel. Do not go to places where you are unable to wear a mask, such as restaurants and some gyms, and avoid eating around others at home and at work until 10 days after the day of your positive test. If an individual has access to a test and wants to test, the best approach is to use an antigen test1 towards the end of the 5-day isolation period. If your test result is positive, you should continue to isolate until day 10. If your test result is positive, you can also choose to test daily and if your test result is negative, you can end isolation, but continue to wear a well-fitting mask around others at home and in public until day 10. Follow additional recommendations for masking and avoiding travel as described above. 1As noted in the labeling for authorized over-the counter antigen tests external icon external icon  : Negative results should be treated as presumptive. Negative results do not rule out SARS-CoV-2 infection and should not be used as the sole basis for treatment or patient management decisions, including infection control decisions. To improve results, antigen tests should be used twice over a three-day period with at least 24 hours and no more than 48 hours between tests. Ending isolation for people who were moderately or very sick from COVID-19 or have a weakened immune system People who are moderately ill from COVID-19 (experiencing symptoms that affect the lungs like shortness of breath or difficulty breathing) should isolate for 10 days and follow all other isolation precautions.  To calculate your 10-day isolation period, day 0 is your first day of symptoms. Day 1 is the first full day after your symptoms developed. If you are unsure if your symptoms are moderate, talk to a healthcare provider for further guidance. People who are very sick from COVID-19 (this means people who were hospitalized or required intensive care or ventilation support) and people who have weakened immune systems might need to isolate at home longer. They may also require testing with a viral test to determine when they can be around others. CDC recommends an isolation period of at least 10 and up to 20 days for people who were very sick from COVID-19 and for people with weakened immune systems. Consult with your healthcare provider about when you can resume being around other people. If you are unsure if your symptoms are severe or if you have a weakened immune system, talk to a healthcare provider for further guidance. People who have a weakened immune system should talk to their healthcare provider about the potential for reduced immune responses to COVID-19 vaccines and the need to continue to follow current prevention measures (including wearing a well-fitting mask and avoiding crowds and poorly ventilated indoor spaces) to protect themselves against COVID-19 until advised otherwise by their healthcare provider. Close contacts of immunocompromised people—including household members—should also be encouraged to receive all recommended COVID-19 vaccine doses to help protect these people.  Isolation in high-risk congregate settings In certain high-risk congregate settings that have high risk of secondary transmission and where it is not feasible to cohort people (such as correctional and detention facilities, homeless shelters, and cruise ships), CDC recommends a 10-day isolation period for residents. During periods of critical staffing shortages, facilities may consider shortening the isolation period for staff to ensure continuity of operations. Decisions to shorten isolation in these settings should be made in consultation with state, local, tribal, or territorial health departments and should take into consideration the context and characteristics of the facility. CDC’s setting-specific guidance provides additional recommendations for these settings. This CDC guidance is meant to supplement—not replace—any federal, state, local, territorial, or tribal health and safety laws, rules, and regulations. \"\n",
        "\n",
        "prediction = run_prediction([\"What do I do if I am exposed to COVID-19?\", \"What should I do if I have a weakened immune system?\", \"How long should I isolate if I get Covid?\"], cdc_guidance)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Qe9bo6KoRsO_"
      },
      "outputs": [],
      "source": [
        "for key, value in prediction.items(): \n",
        "  print(value)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "DR3O-ygQ7boy"
      },
      "source": [
        ""
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "sLpCCAy_7vey"
      },
      "source": [
        "## 6.0 Conclusion\n",
        "\n",
        "ALBERT is a highly accesible classifier for anyone who has enough RAM and GPU to run it. It is marketed as a lighter, higher speed version of the BERT classifier, but from what I found it's speed is highly dependent on the amount of context provided. With smaller amounts of context, BERT ran much faster. Overall testing the model took around 2 hours on Google Colab Pro GPU but could not run locally on my machine. "
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "-r-ttItl8eb3"
      },
      "source": [
        ""
      ]
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "collapsed_sections": [],
      "name": "Albert.ipynb",
      "provenance": [],
      "mount_file_id": "1NXZ55t8AtduVSlK_8oaFSVbP7lHAP4m9",
      "authorship_tag": "ABX9TyNZidBHFlbfwUWx+EzDR/qn",
      "include_colab_link": true
    },
    "gpuClass": "standard",
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    },
    "widgets": {
      "application/vnd.jupyter.widget-state+json": {
        "2906947dbb0445328c2facc291c9678a": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_3d8b3a25bd0841efa4407409f787d4ce",
              "IPY_MODEL_ebbeb5a4d17640188f5dea555c7a25b7",
              "IPY_MODEL_0dc5d2ff49ec403f8d08a600b0aa7ab4"
            ],
            "layout": "IPY_MODEL_02027cd601ba47dfad201edaa9beeda5"
          }
        },
        "3d8b3a25bd0841efa4407409f787d4ce": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_4b0f54d1534d4d8c9012cdc079dcd161",
            "placeholder": "​",
            "style": "IPY_MODEL_fda115d9eb9c45e198da067396d4b56c",
            "value": "Downloading builder script: 100%"
          }
        },
        "ebbeb5a4d17640188f5dea555c7a25b7": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_3c5ccbd8e3e84919954767fe3d9cea3f",
            "max": 7791,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_449f5b23d8654c58b0080da5feca8ec4",
            "value": 7791
          }
        },
        "0dc5d2ff49ec403f8d08a600b0aa7ab4": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_a55a70987b2244dea1278402348a821a",
            "placeholder": "​",
            "style": "IPY_MODEL_1d6aad3e74e14a61b3d2a699618b592a",
            "value": " 7.79k/7.79k [00:00&lt;00:00, 227kB/s]"
          }
        },
        "02027cd601ba47dfad201edaa9beeda5": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "4b0f54d1534d4d8c9012cdc079dcd161": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "fda115d9eb9c45e198da067396d4b56c": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "3c5ccbd8e3e84919954767fe3d9cea3f": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "449f5b23d8654c58b0080da5feca8ec4": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "a55a70987b2244dea1278402348a821a": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "1d6aad3e74e14a61b3d2a699618b592a": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        }
      }
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}